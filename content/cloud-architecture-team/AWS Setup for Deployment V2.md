# Tutorial: Deploying a Machine Learning Model Using AWS ECS, ECR, S3, and ALB

## Objective
This guide outlines the steps for deploying a machine learning model using AWS Elastic Container Service (ECS), Amazon Elastic Container Registry (ECR), Amazon S3, and an Application Load Balancer (ALB). This setup ensures scalability, flexibility, and high availability, making it more suitable for high-traffic and large-model deployments compared to AWS Lambda + API Gateway.

### The setup includes:
- ‚úÖ Containerizing the model with Docker and pushing it to Amazon ECR.
- ‚úÖ Deploying the model on ECS using Fargate (serverless) or EC2 (manual scaling).
- ‚úÖ Using ALB to route external traffic to ECS tasks securely.
- ‚úÖ Loading the ML model dynamically from S3 to keep containers stateless.

---

## 1Ô∏è‚É£ Preparing the Model and Uploading to S3
Since ECS containers are stateless, the ML model should be stored externally (not inside the container).

‚úÖ **Upload the model to S3:**
```bash
aws s3 cp model.keras s3://your-bucket-name/model.keras
```

‚úÖ **Modify the Flask app to load the model from S3 on startup:**
```python
import boto3
import os
from tensorflow.keras.models import load_model

S3_BUCKET = "your-bucket-name"
MODEL_FILE = "model.keras"
LOCAL_MODEL_PATH = f"/app/{MODEL_FILE}"

# Download model if not already present
if not os.path.exists(LOCAL_MODEL_PATH):
    s3 = boto3.client("s3")
    print(f"üì• Downloading model from S3: {S3_BUCKET}/{MODEL_FILE}")
    s3.download_file(S3_BUCKET, MODEL_FILE, LOCAL_MODEL_PATH)

# Load model
model = load_model(LOCAL_MODEL_PATH)
print("‚úÖ Model loaded successfully.")
```

---

## 2Ô∏è‚É£ Creating the Docker Image
A Dockerfile is used to package the application with dependencies.

‚úÖ **Dockerfile:**
```dockerfile
# Use an official lightweight Python image
FROM python:3.12-slim

# Set the working directory in the container
WORKDIR /app

# Copy the application files into the container
COPY . /app

# Install dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Expose Flask's default port
EXPOSE 8080

# Start the Flask app
CMD ["gunicorn", "-b", "0.0.0.0:8080", "app:app"]
```

---

## 3Ô∏è‚É£ Building and Testing Locally

‚úÖ **Build the Docker image:**
```bash
docker build -t flask-ecs-app .
```
‚úÖ **Run it locally:**
```bash
docker run -p 8080:8080 flask-ecs-app
```
‚úÖ **Test the API:**
```bash
curl -X GET http://127.0.0.1:8080/
```

---

## 4Ô∏è‚É£ Pushing the Image to AWS Elastic Container Registry (ECR)

‚úÖ **1. Create an ECR Repository:**
```bash
aws ecr create-repository --repository-name flask-ecs-app
```

‚úÖ **2. Authenticate Docker with AWS:**
```bash
aws ecr get-login-password --region your-region | docker login --username AWS --password-stdin your-aws-account-id.dkr.ecr.your-region.amazonaws.com
```

‚úÖ **3. Tag & Push Docker Image to ECR:**
```bash
docker tag flask-ecs-app:latest your-aws-account-id.dkr.ecr.your-region.amazonaws.com/flask-ecs-app:latest
docker push your-aws-account-id.dkr.ecr.your-region.amazonaws.com/flask-ecs-app:latest
```

---

## 5Ô∏è‚É£ Deploying the Model Using AWS ECS

‚úÖ **1. Create an ECS Task Definition**
- Go to **ECS Console ‚Üí Task Definitions ‚Üí Create New Task Definition**.
- Choose **Fargate (serverless)** or **EC2 (manual scaling)**.
- Add a container definition:
  - **Image:** ECR URL (`your-aws-account-id.dkr.ecr.your-region.amazonaws.com/flask-ecs-app:latest`).
  - **Port Mapping:** 8080 (match Flask app).

‚úÖ **2. Create an ECS Cluster**
- Go to **ECS Console ‚Üí Clusters ‚Üí Create Cluster**.
- Choose **Fargate (for serverless)** or **EC2 (for manual scaling)**.

‚úÖ **3. Deploy an ECS Service**
- Go to **your Cluster ‚Üí Create Service**.
- **Launch Type:** Choose **Fargate (recommended)**.
- **Task Definition:** Select the one created earlier.
- **VPC & Subnets:** Select AWS networking settings.
- **Auto Scaling:** Adjust based on expected traffic.

---

## 6Ô∏è‚É£ Configuring the Application Load Balancer (ALB) for Public Access
To expose the ECS service securely, we use ALB (Application Load Balancer) to route traffic.

‚úÖ **Steps to Set Up ALB**
1. **Create an ALB** in **AWS Console ‚Üí EC2 ‚Üí Load Balancers**.
2. **Attach the ALB to a Public Subnet**.
3. **Create a Target Group**:
   - Register the **ECS service** as a target.
   - Use **port 8080** (Flask app).
4. **Configure Listeners**:
   - **Port 80** ‚Üí Redirect to **8080** (for HTTP traffic).
   - **Port 443** ‚Üí Enable **SSL** (optional for HTTPS).
5. **Set Up SSL Certificate**
   - **You cannot get a free SSL certificate directly for ALB.**
   - Instead, **purchase a domain from Route 53**.
   - **Use AWS Certificate Manager (ACM)** to generate an SSL certificate.
   - **Create subdomains** for different models (e.g., `resnet.example.com`, `catboost.example.com`). Details you can check documentation on how frontend and backend are connected

5. **Deploy the ECS Service with ALB integration**.

‚úÖ **Get the ALB URL and test the API:**
```bash
curl -X POST -F "image=@test.jpg" http://your-alb-dns-name:8080/predict
```

---

## 7Ô∏è‚É£ Final Summary: Why ECS + ALB is Better Than Lambda + API Gateway

| Feature              | ECS + ALB                           | Lambda + API Gateway           |
|----------------------|----------------------------------|------------------------------|
| **Model Size Limit** | No limit (can pull large models from S3) | 50 MB (Lambda) |
| **Cold Start Latency** | Lower (Containers are always running) | Higher (Cold starts in Lambda) |
| **Scalability**      | Auto Scales with Load Balancer   | Auto Scales (but may hit throttling) |
| **Stateful Processing** | ‚úÖ Supports persistent connections | ‚ùå Stateless only |
| **Custom Dependencies** | ‚úÖ Full control via Docker | ‚ùå Limited to Lambda Layers |
| **Long-Running Inference** | ‚úÖ Can handle batch & real-time inference | ‚ùå Hard limit of 15 minutes per execution |

üìå **Key Takeaways**
- ‚úÖ **ECS + ALB** is more suitable for **large ML models** and **high-traffic applications**.
- ‚úÖ **Lambda + API Gateway** is better for **small functions**, **low-latency**, and **event-driven workflows**.
- ‚úÖ **Using ALB** improves performance and allows better scaling.
- ‚úÖ **Keeping the model in S3** makes ECS containers stateless and flexible.

üìå **Next Steps**
- **Monitor ECS task performance** using CloudWatch Logs.
- **Set up Auto Scaling** for ECS tasks based on demand.
- **Implement HTTPS for ALB** with SSL certificates.
- **Optimize costs** by switching between **EC2 and Fargate** based on usage.

---

### üîó **Resource:**
- [GitHub Repository](https://github.com/kshannon-ucsd/24wi-dsc180-profile/tree/ECS-ResNet)
